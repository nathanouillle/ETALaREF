{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78251ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.whisper_song import transcribe_folder\n",
    "from src.ui import chatbot_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed7343c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dceb69b37b4a9db6c2c9c065352b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border_bottom='1px solid #444', border_left='1px solid #444', border_rightâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(async () => {\n  const durationSec = 5;\n  const filename = 'voice_1756920706_6296e890add1437b83b15ad200fc6a15.wav';\n  // Permission + stream\n  let stream;\n  try {\n    stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n  } catch (e) {\n    alert(\"Microphone permission denied or unavailable.\");\n    return;\n  }\n\n  // Use WebAudio to collect PCM samples; then encode WAV\n  const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });\n  const source = audioCtx.createMediaStreamSource(stream);\n\n  // ScriptProcessor is deprecated but broadly supported; fine for quick hack\n  const bufferSize = 4096;\n  const processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);\n  const samples = [];\n\n  processor.onaudioprocess = (event) => {\n    const input = event.inputBuffer.getChannelData(0);\n    // copy the chunk (Float32Array)\n    samples.push(new Float32Array(input));\n  };\n\n  source.connect(processor);\n  processor.connect(audioCtx.destination);\n\n  // Record for N seconds\n  await new Promise(r => setTimeout(r, durationSec * 1000));\n\n  // Stop\n  processor.disconnect();\n  source.disconnect();\n  stream.getTracks().forEach(t => t.stop());\n  audioCtx.close();\n\n  // Merge samples into one Float32Array\n  let length = 0;\n  for (const s of samples) length += s.length;\n  const merged = new Float32Array(length);\n  let offset = 0;\n  for (const s of samples) { merged.set(s, offset); offset += s.length; }\n\n  // Encode 16-bit PCM WAV\n  function floatTo16BitPCM(float32) {\n    const out = new Int16Array(float32.length);\n    for (let i = 0; i < float32.length; i++) {\n      const s = Math.max(-1, Math.min(1, float32[i]));\n      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;\n    }\n    return out;\n  }\n\n  function writeString(view, offset, str) {\n    for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));\n  }\n\n  function encodeWAV(samples, sampleRate) {\n    const pcm = floatTo16BitPCM(samples);\n    const buffer = new ArrayBuffer(44 + pcm.length * 2);\n    const view = new DataView(buffer);\n\n    /* RIFF header */\n    writeString(view, 0, 'RIFF');\n    view.setUint32(4, 36 + pcm.length * 2, true);\n    writeString(view, 8, 'WAVE');\n    /* fmt chunk */\n    writeString(view, 12, 'fmt ');\n    view.setUint32(16, 16, true);\n    view.setUint16(20, 1, true); // PCM\n    view.setUint16(22, 1, true); // mono\n    view.setUint32(24, sampleRate, true);\n    view.setUint32(28, sampleRate * 2, true); // byte rate\n    view.setUint16(32, 2, true); // block align\n    view.setUint16(34, 16, true); // bits per sample\n    /* data chunk */\n    writeString(view, 36, 'data');\n    view.setUint32(40, pcm.length * 2, true);\n\n    // PCM samples\n    const pcmBytes = new Int16Array(buffer, 44, pcm.length);\n    pcmBytes.set(pcm);\n\n    return buffer;\n  }\n\n  const wavBuffer = encodeWAV(merged, 44100);\n\n  // Convert to base64\n  const bytes = new Uint8Array(wavBuffer);\n  let binary = '';\n  for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);\n  const b64 = btoa(binary);\n\n  // Call back into Python (classic Notebook)\n  if (window.Jupyter && Jupyter.notebook && Jupyter.notebook.kernel) {\n    const py = \"_chatbot_recv_6296e890add1437b83b15ad200fc6a15(\" + JSON.stringify(b64) + \",\" + JSON.stringify(filename) + \")\";\n    Jupyter.notebook.kernel.execute(py);\n  } else {\n    alert(\"Cannot reach Python kernel from JS in this environment.\");\n  }\n})();\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(async () => {\n  const durationSec = 5;\n  const filename = 'voice_1756920712_6296e890add1437b83b15ad200fc6a15.wav';\n  // Permission + stream\n  let stream;\n  try {\n    stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n  } catch (e) {\n    alert(\"Microphone permission denied or unavailable.\");\n    return;\n  }\n\n  // Use WebAudio to collect PCM samples; then encode WAV\n  const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });\n  const source = audioCtx.createMediaStreamSource(stream);\n\n  // ScriptProcessor is deprecated but broadly supported; fine for quick hack\n  const bufferSize = 4096;\n  const processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);\n  const samples = [];\n\n  processor.onaudioprocess = (event) => {\n    const input = event.inputBuffer.getChannelData(0);\n    // copy the chunk (Float32Array)\n    samples.push(new Float32Array(input));\n  };\n\n  source.connect(processor);\n  processor.connect(audioCtx.destination);\n\n  // Record for N seconds\n  await new Promise(r => setTimeout(r, durationSec * 1000));\n\n  // Stop\n  processor.disconnect();\n  source.disconnect();\n  stream.getTracks().forEach(t => t.stop());\n  audioCtx.close();\n\n  // Merge samples into one Float32Array\n  let length = 0;\n  for (const s of samples) length += s.length;\n  const merged = new Float32Array(length);\n  let offset = 0;\n  for (const s of samples) { merged.set(s, offset); offset += s.length; }\n\n  // Encode 16-bit PCM WAV\n  function floatTo16BitPCM(float32) {\n    const out = new Int16Array(float32.length);\n    for (let i = 0; i < float32.length; i++) {\n      const s = Math.max(-1, Math.min(1, float32[i]));\n      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;\n    }\n    return out;\n  }\n\n  function writeString(view, offset, str) {\n    for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));\n  }\n\n  function encodeWAV(samples, sampleRate) {\n    const pcm = floatTo16BitPCM(samples);\n    const buffer = new ArrayBuffer(44 + pcm.length * 2);\n    const view = new DataView(buffer);\n\n    /* RIFF header */\n    writeString(view, 0, 'RIFF');\n    view.setUint32(4, 36 + pcm.length * 2, true);\n    writeString(view, 8, 'WAVE');\n    /* fmt chunk */\n    writeString(view, 12, 'fmt ');\n    view.setUint32(16, 16, true);\n    view.setUint16(20, 1, true); // PCM\n    view.setUint16(22, 1, true); // mono\n    view.setUint32(24, sampleRate, true);\n    view.setUint32(28, sampleRate * 2, true); // byte rate\n    view.setUint16(32, 2, true); // block align\n    view.setUint16(34, 16, true); // bits per sample\n    /* data chunk */\n    writeString(view, 36, 'data');\n    view.setUint32(40, pcm.length * 2, true);\n\n    // PCM samples\n    const pcmBytes = new Int16Array(buffer, 44, pcm.length);\n    pcmBytes.set(pcm);\n\n    return buffer;\n  }\n\n  const wavBuffer = encodeWAV(merged, 44100);\n\n  // Convert to base64\n  const bytes = new Uint8Array(wavBuffer);\n  let binary = '';\n  for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);\n  const b64 = btoa(binary);\n\n  // Call back into Python (classic Notebook)\n  if (window.Jupyter && Jupyter.notebook && Jupyter.notebook.kernel) {\n    const py = \"_chatbot_recv_6296e890add1437b83b15ad200fc6a15(\" + JSON.stringify(b64) + \",\" + JSON.stringify(filename) + \")\";\n    Jupyter.notebook.kernel.execute(py);\n  } else {\n    alert(\"Cannot reach Python kernel from JS in this environment.\");\n  }\n})();\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(async () => {\n  const durationSec = 5;\n  const filename = 'voice_1756920808_6296e890add1437b83b15ad200fc6a15.wav';\n  // Permission + stream\n  let stream;\n  try {\n    stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n  } catch (e) {\n    alert(\"Microphone permission denied or unavailable.\");\n    return;\n  }\n\n  // Use WebAudio to collect PCM samples; then encode WAV\n  const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 44100 });\n  const source = audioCtx.createMediaStreamSource(stream);\n\n  // ScriptProcessor is deprecated but broadly supported; fine for quick hack\n  const bufferSize = 4096;\n  const processor = audioCtx.createScriptProcessor(bufferSize, 1, 1);\n  const samples = [];\n\n  processor.onaudioprocess = (event) => {\n    const input = event.inputBuffer.getChannelData(0);\n    // copy the chunk (Float32Array)\n    samples.push(new Float32Array(input));\n  };\n\n  source.connect(processor);\n  processor.connect(audioCtx.destination);\n\n  // Record for N seconds\n  await new Promise(r => setTimeout(r, durationSec * 1000));\n\n  // Stop\n  processor.disconnect();\n  source.disconnect();\n  stream.getTracks().forEach(t => t.stop());\n  audioCtx.close();\n\n  // Merge samples into one Float32Array\n  let length = 0;\n  for (const s of samples) length += s.length;\n  const merged = new Float32Array(length);\n  let offset = 0;\n  for (const s of samples) { merged.set(s, offset); offset += s.length; }\n\n  // Encode 16-bit PCM WAV\n  function floatTo16BitPCM(float32) {\n    const out = new Int16Array(float32.length);\n    for (let i = 0; i < float32.length; i++) {\n      const s = Math.max(-1, Math.min(1, float32[i]));\n      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;\n    }\n    return out;\n  }\n\n  function writeString(view, offset, str) {\n    for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));\n  }\n\n  function encodeWAV(samples, sampleRate) {\n    const pcm = floatTo16BitPCM(samples);\n    const buffer = new ArrayBuffer(44 + pcm.length * 2);\n    const view = new DataView(buffer);\n\n    /* RIFF header */\n    writeString(view, 0, 'RIFF');\n    view.setUint32(4, 36 + pcm.length * 2, true);\n    writeString(view, 8, 'WAVE');\n    /* fmt chunk */\n    writeString(view, 12, 'fmt ');\n    view.setUint32(16, 16, true);\n    view.setUint16(20, 1, true); // PCM\n    view.setUint16(22, 1, true); // mono\n    view.setUint32(24, sampleRate, true);\n    view.setUint32(28, sampleRate * 2, true); // byte rate\n    view.setUint16(32, 2, true); // block align\n    view.setUint16(34, 16, true); // bits per sample\n    /* data chunk */\n    writeString(view, 36, 'data');\n    view.setUint32(40, pcm.length * 2, true);\n\n    // PCM samples\n    const pcmBytes = new Int16Array(buffer, 44, pcm.length);\n    pcmBytes.set(pcm);\n\n    return buffer;\n  }\n\n  const wavBuffer = encodeWAV(merged, 44100);\n\n  // Convert to base64\n  const bytes = new Uint8Array(wavBuffer);\n  let binary = '';\n  for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);\n  const b64 = btoa(binary);\n\n  // Call back into Python (classic Notebook)\n  if (window.Jupyter && Jupyter.notebook && Jupyter.notebook.kernel) {\n    const py = \"_chatbot_recv_6296e890add1437b83b15ad200fc6a15(\" + JSON.stringify(b64) + \",\" + JSON.stringify(filename) + \")\";\n    Jupyter.notebook.kernel.execute(py);\n  } else {\n    alert(\"Cannot reach Python kernel from JS in this environment.\");\n  }\n})();\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ChatBot():\n",
    "    def __init__(self, db=None):\n",
    "        self.db = db\n",
    "\n",
    "    def __call__(self, msg):\n",
    "        if msg.lower() == 'image':\n",
    "                return f\"I received:'{msg}'\"\n",
    "        if msg.lower() == 'hello':\n",
    "            return 'world'\n",
    "\n",
    "bot = ChatBot()\n",
    "\n",
    "chatbot_ui(bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88effe65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchalina-r",
   "language": "python",
   "name": "matchalina-r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
